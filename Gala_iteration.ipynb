{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab's New Code Editor",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anu-kriti/AA/blob/master/Gala_iteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwl_VG7IIUW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "from numpy import load\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import distutils\n",
        "if distutils.version.LooseVersion(tf.__version__) < '1.14':\n",
        "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from zipfile import ZipFile \n",
        "\n",
        "file_name = '9d34462453e311ea.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    zip.extractall()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXaBPBdxesXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYwWv_pULvIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "39c5d4b0-f8ed-4896-92c0-a198372e09fd"
      },
      "source": [
        "path = 'dataset'\n",
        "\n",
        "train_df = pd.read_csv(path+'/train.csv')\n",
        "test_df = pd.read_csv(path+'/test.csv')\n",
        "train_df.Class.value_counts(normalize = True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Food                    0.380745\n",
              "Attire                  0.282634\n",
              "misc                    0.212435\n",
              "Decorationandsignage    0.124185\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlvo4aIpLzdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "cf4070af-494a-4bf5-a8ca-492fdaae1eee"
      },
      "source": [
        "class_map = {\n",
        "    'Food': 0,\n",
        "    'Attire': 1,\n",
        "    'Decorationandsignage': 2,\n",
        "    'misc': 3\n",
        "}\n",
        "\n",
        "inverse_class_map = {\n",
        "    0: 'Food',\n",
        "    1: 'Attire',\n",
        "    2: 'Decorationandsignage',\n",
        "    3: 'misc'\n",
        "}\n",
        "train_df['Class'] = train_df['Class'].map(class_map).astype(np.uint8)\n",
        "train_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image7042.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image3327.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image10335.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image8019.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image2128.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Image  Class\n",
              "0   image7042.jpg      0\n",
              "1   image3327.jpg      3\n",
              "2  image10335.jpg      1\n",
              "3   image8019.jpg      0\n",
              "4   image2128.jpg      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVDa2LPbKoz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = 'dataset/Train Images/'\n",
        "test_path = 'dataset/Test Images/'\n",
        "\n",
        "h, w = 224, 224\n",
        "\n",
        "train_images, train_labels = [], []\n",
        "\n",
        "for i in range(len(train_df.Image)):\n",
        "    train_image = cv2.imread(train_path + str(train_df.Image[i]))\n",
        "    train_image = cv2.resize(train_image, (h, w))\n",
        "    train_images.append(train_image)\n",
        "    train_labels.append(train_df.Class[i])\n",
        "\n",
        "test_images = []\n",
        "\n",
        "for i in range(len(test_df.Image)):\n",
        "    test_image = cv2.imread(test_path + str(test_df.Image[i]))\n",
        "    test_image = cv2.resize(test_image, (h, w))\n",
        "    test_images.append(test_image)\n",
        "\n",
        "train_images = np.array(train_images).astype('float32')\n",
        "#train_images = train_images.astype('float32')/255.0\n",
        "test_images = np.array(test_images).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTAe06KiL1RK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_images, to_categorical(train_labels), test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaieWw6bNYkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4ef687b-47e3-4757-a14e-95acddc9de88"
      },
      "source": [
        "X_train.shape,y_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4786, 224, 224, 3), (4786, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcIGSDjxTn-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "1ba99e8b-e1ca-4deb-9ac4-1e6312577db1"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 1152244118631715023, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 12122589873734908250\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 3707463848756320324\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 7470045594\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 16168383393346113427\n",
              " physical_device_desc: \"device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glgC5sXROsjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a77d9bf-9740-4367-b666-e8e85b379d68"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False, \n",
        "    input_shape=(h, w, 3), \n",
        "    pooling='avg'\n",
        ")\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "  base_model,\n",
        "  #Dropout(0.2),\n",
        "    Dense(512, activation = \"relu\"),\n",
        "  Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True, \n",
        "            height_shift_range = 0.1,\n",
        "            width_shift_range = 0.1,\n",
        "            rotation_range = 10)\n",
        "\n",
        "\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), validation_data= (X_test, y_test),\n",
        "                    steps_per_epoch = len(X_train) / batch_size, epochs=epochs)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 24,638,852\n",
            "Trainable params: 1,051,140\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "149/149 [============================>.] - ETA: 0s - loss: 0.8523 - acc: 0.6946Epoch 1/10\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 8s 7ms/sample - loss: 0.7652 - acc: 0.7143\n",
            "150/149 [==============================] - 63s 420ms/step - loss: 0.8520 - acc: 0.6943 - val_loss: 0.7323 - val_acc: 0.7143\n",
            "Epoch 2/10\n",
            "149/149 [============================>.] - ETA: 0s - loss: 0.6148 - acc: 0.7627Epoch 1/10\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 6s 5ms/sample - loss: 0.8992 - acc: 0.7251\n",
            "150/149 [==============================] - 53s 353ms/step - loss: 0.6141 - acc: 0.7628 - val_loss: 0.7817 - val_acc: 0.7251\n",
            "Epoch 3/10\n",
            "149/149 [============================>.] - ETA: 0s - loss: 0.5349 - acc: 0.7970Epoch 1/10\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 6s 5ms/sample - loss: 0.8961 - acc: 0.7360\n",
            "150/149 [==============================] - 52s 347ms/step - loss: 0.5338 - acc: 0.7975 - val_loss: 0.7341 - val_acc: 0.7360\n",
            "Epoch 4/10\n",
            "149/149 [============================>.] - ETA: 0s - loss: 0.4850 - acc: 0.8174Epoch 1/10\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 6s 5ms/sample - loss: 0.7589 - acc: 0.7419\n",
            "150/149 [==============================] - 51s 342ms/step - loss: 0.4835 - acc: 0.8180 - val_loss: 0.7625 - val_acc: 0.7419\n",
            "Epoch 5/10\n",
            "149/149 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8317Epoch 1/10\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 6s 5ms/sample - loss: 0.8726 - acc: 0.7402\n",
            "150/149 [==============================] - 52s 346ms/step - loss: 0.4496 - acc: 0.8320 - val_loss: 0.8265 - val_acc: 0.7402\n",
            "Epoch 6/10\n",
            "149/149 [============================>.] - ETA: 0s - loss: 0.4247 - acc: 0.8361Epoch 1/10\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 6s 5ms/sample - loss: 0.7387 - acc: 0.7226\n",
            "150/149 [==============================] - 53s 351ms/step - loss: 0.4244 - acc: 0.8360 - val_loss: 0.7922 - val_acc: 0.7226\n",
            "Epoch 7/10\n",
            "149/149 [============================>.] - ETA: 0s - loss: 0.3848 - acc: 0.8534Epoch 1/10\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 6s 5ms/sample - loss: 0.8225 - acc: 0.7393\n",
            "150/149 [==============================] - 53s 353ms/step - loss: 0.3842 - acc: 0.8537 - val_loss: 0.8017 - val_acc: 0.7393\n",
            "Epoch 8/10\n",
            "149/149 [============================>.] - ETA: 0s - loss: 0.3722 - acc: 0.8616Epoch 1/10\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 6s 5ms/sample - loss: 0.8194 - acc: 0.7352\n",
            "150/149 [==============================] - 52s 349ms/step - loss: 0.3727 - acc: 0.8611 - val_loss: 0.8038 - val_acc: 0.7352\n",
            "Epoch 9/10\n",
            "149/149 [============================>.] - ETA: 0s - loss: 0.3510 - acc: 0.8662Epoch 1/10\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 6s 5ms/sample - loss: 0.7903 - acc: 0.7444\n",
            "150/149 [==============================] - 52s 349ms/step - loss: 0.3517 - acc: 0.8656 - val_loss: 0.8282 - val_acc: 0.7444\n",
            "Epoch 10/10\n",
            "149/149 [============================>.] - ETA: 0s - loss: 0.3273 - acc: 0.8784Epoch 1/10\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 6s 5ms/sample - loss: 0.9012 - acc: 0.7277\n",
            "150/149 [==============================] - 52s 349ms/step - loss: 0.3268 - acc: 0.8786 - val_loss: 0.8854 - val_acc: 0.7277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f50ee88f048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi0nEEbPV-S4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "537442a0-c175-411f-a709-91f95f3c6373"
      },
      "source": [
        "labels = model.predict(test_images)\n",
        "label = [np.argmax(i) for i in labels]\n",
        "class_label = [inverse_class_map[x] for x in label]\n",
        "print(class_label[:3])\n",
        "\n",
        "model.save_weights('./resnet_1itr_model.h5', overwrite=True)\n",
        "\n",
        "from numpy import savetxt\n",
        "savetxt('resnet_1itr_prob.csv', labels, delimiter=',')\n",
        "\n",
        "submission = pd.DataFrame({'Image': test_df.Image, 'Class': class_label })\n",
        "submission.head()\n",
        "\n",
        "submission.Class.value_counts()\n",
        "submission.to_csv('resnet_1stitr_results.csv', index=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Attire', 'Food', 'misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_zlMeWMWzIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "efd2129f-49e9-4046-a6fc-2d6d2d9779ab"
      },
      "source": [
        "submission.Class.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Food                    1160\n",
              "Attire                  1033\n",
              "misc                     630\n",
              "Decorationandsignage     396\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-bRpYarYnUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape= X_train.shape[1:]))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape= X_train.shape[1:]))\n",
        "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(256))\n",
        "  model.add(tf.keras.layers.Activation('elu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(4))\n",
        "  model.add(tf.keras.layers.Activation('softmax'))\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNJ13q7YbjoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "f8bd0cdb-45f9-4936-c3ae-4bc16764ee67"
      },
      "source": [
        "import os\n",
        "\n",
        "#with strategy.scope():\n",
        "model = create_model()\n",
        "#model.compile(\n",
        " #     optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
        "  #    loss='sparse_categorical_crossentropy',\n",
        "   #   metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#model.summary()\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_3 (Batch (None, 224, 224, 3)       12        \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 224, 224, 64)      4864      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 112, 112, 128)     204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 256)       819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 200704)            0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               51380480  \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 1028      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 52,411,536\n",
            "Trainable params: 52,411,146\n",
            "Non-trainable params: 390\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1kT8zzAJZJw",
        "colab_type": "code",
        "outputId": "b60a4371-2f16-4dfc-9a47-11a6de54bbee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size = 32,\n",
        "   # steps_per_epoch= 12\n",
        "    validation_data=(X_test, y_test)\n",
        "    #validation_freq=17\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4786 samples, validate on 1197 samples\n",
            "Epoch 1/5\n",
            "4786/4786 [==============================] - 49s 10ms/sample - loss: 16.5710 - acc: 0.2860 - val_loss: 1.3339 - val_acc: 0.3851\n",
            "Epoch 2/5\n",
            "4786/4786 [==============================] - 46s 10ms/sample - loss: 1.7979 - acc: 0.3055 - val_loss: 1.3357 - val_acc: 0.3885\n",
            "Epoch 3/5\n",
            "4786/4786 [==============================] - 46s 10ms/sample - loss: 1.7614 - acc: 0.2944 - val_loss: 1.3268 - val_acc: 0.3835\n",
            "Epoch 4/5\n",
            "4786/4786 [==============================] - 46s 10ms/sample - loss: 1.7116 - acc: 0.2965 - val_loss: 1.3242 - val_acc: 0.3835\n",
            "Epoch 5/5\n",
            "4786/4786 [==============================] - 46s 10ms/sample - loss: 1.6308 - acc: 0.3201 - val_loss: 1.3209 - val_acc: 0.3835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f50d60ee940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1cRuybtYSBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c1ead31-e73a-4cce-f34a-77b2a721e974"
      },
      "source": [
        "labels = model.predict(test_images)\n",
        "label = [np.argmax(i) for i in labels]\n",
        "class_label = [inverse_class_map[x] for x in label]\n",
        "print(class_label[:3])\n",
        "\n",
        "model.save_weights('./basic_model_1itr_model.h5', overwrite=True)\n",
        "\n",
        "from numpy import savetxt\n",
        "savetxt('basic_model_1itr_prob.csv', labels, delimiter=',')\n",
        "\n",
        "submission = pd.DataFrame({'Image': test_df.Image, 'Class': class_label })\n",
        "submission.head()\n",
        "\n",
        "submission.Class.value_counts()\n",
        "submission.to_csv('basic_model_1stitr_results.csv', index=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Food', 'Food', 'Food']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb9z0iYXYaxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "70e63676-7938-4613-95ab-b6710d01f91f"
      },
      "source": [
        "submission.Class.value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Food      3206\n",
              "Attire       8\n",
              "misc         5\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1CLuH_ghBqi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "807ccb37-de0e-4af2-b93b-eac8d8abfdde"
      },
      "source": [
        "!pip install efficientnet"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading https://files.pythonhosted.org/packages/28/91/67848a143b54c331605bfba5fd31cf4e9db13d2e429d103fe807acc3bcf4/efficientnet-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.8.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.12.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (46.0.0)\n",
            "Installing collected packages: efficientnet\n",
            "Successfully installed efficientnet-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoN3BH9eXnk-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cdcb44f-d41e-41fb-d1b7-a46b1b00ba33"
      },
      "source": [
        "import math, re, os\n",
        "import numpy as np\n",
        "import skimage\n",
        "from matplotlib import pyplot as plt\n",
        "#from kaggle_datasets import KaggleDatasets\n",
        "import efficientnet  as efn\n",
        "import tensorflow as tf, tensorflow.keras.backend as K\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSkeUFhFXnoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "c5b4531b-5f0b-4a70-a590-57ecf66fc398"
      },
      "source": [
        "#pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
        "#pretrained_model = efn.EfficientNetB7(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
        "pretrained_model = DenseNet201(weights='imagenet', include_top=False ,input_shape=[224,224, 3])\n",
        "#pretrained_model.trainable = False # tramsfer learning\n",
        "pretrained_model.trainable = True\n",
        "model_1 = tf.keras.Sequential([\n",
        "        pretrained_model,\n",
        "        #tf.keras.layers.Conv2D(filters=1024,kernel_size=3,strides=(2,2),padding='same'),\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(512, activation = \"relu\"),\n",
        "        tf.keras.layers.Dense(4, activation='softmax')\n",
        "    ])\n",
        "model_1.compile(\n",
        "    optimizer = 'adam',\n",
        "    #optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")\n",
        "model_1.summary()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74842112/74836368 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet201 (Model)          (None, 7, 7, 1920)        18321984  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               983552    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 19,307,588\n",
            "Trainable params: 19,078,532\n",
            "Non-trainable params: 229,056\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxJUzJoYXnrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "8e686e13-ee44-4d24-e848-3fedc4232b16"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "            rescale            = 1./255,\n",
        "            shear_range        = 0.2,\n",
        "            zoom_range         = 0.2,\n",
        "            horizontal_flip    = True, \n",
        "            height_shift_range = 0.1,\n",
        "            width_shift_range  = 0.1,\n",
        "            rotation_range     = 10)\n",
        "\n",
        "\n",
        "model_1.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), validation_data= (X_test, y_test),\n",
        "                    steps_per_epoch = len(X_train) / batch_size, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "149/149 [============================>.] - ETA: 4s - loss: 0.9469 - acc: 0.6165 Epoch 1/5\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 36s 30ms/sample - loss: 68.6847 - acc: 0.1587\n",
            "150/149 [==============================] - 1214s 8s/step - loss: 0.9472 - acc: 0.6162 - val_loss: 70.1739 - val_acc: 0.1587\n",
            "Epoch 2/5\n",
            "149/149 [============================>.] - ETA: 4s - loss: 0.8995 - acc: 0.6420 Epoch 1/5\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 34s 29ms/sample - loss: 692.1997 - acc: 0.1236\n",
            "150/149 [==============================] - 1198s 8s/step - loss: 0.8999 - acc: 0.6421 - val_loss: 675.4382 - val_acc: 0.1236\n",
            "Epoch 3/5\n",
            "149/149 [============================>.] - ETA: 4s - loss: 0.8465 - acc: 0.6576 Epoch 1/5\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 34s 29ms/sample - loss: 715.9881 - acc: 0.1195\n",
            "150/149 [==============================] - 1155s 8s/step - loss: 0.8461 - acc: 0.6578 - val_loss: 724.2254 - val_acc: 0.1195\n",
            "Epoch 4/5\n",
            "149/149 [============================>.] - ETA: 4s - loss: 0.8202 - acc: 0.6725 Epoch 1/5\n",
            "1197/149 [================================================================================================================================================================================================================================================] - 37s 31ms/sample - loss: 492.6052 - acc: 0.1270\n",
            "150/149 [==============================] - 1160s 8s/step - loss: 0.8214 - acc: 0.6720 - val_loss: 485.3948 - val_acc: 0.1270\n",
            "Epoch 5/5\n",
            " 58/149 [==========>...................] - ETA: 11:30 - loss: 0.7895 - acc: 0.6853"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37mPe4DAXnua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKcgJNd3ZLWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c3788338-7e01-40b3-aac1-cc1262c053c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd4XHL3Aam3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu = 'grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "strategy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY7vfdgnKCrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_NAMES = ['Food', 'Attire', 'Decorationandsignage', 'misc']\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}